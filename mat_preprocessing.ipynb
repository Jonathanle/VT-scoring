{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import tomni\n",
    "from matplotlib import cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This snippet gets the list of .mat files under each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of subjects:  10\n",
      "['SARC_UVA_0010_AUTO_FUNCTION_1_103.mat', 'SARC_UVA_0010_AUTO_FUNCTION_LAX_117.mat', 'SARC_UVA_0010_AUTO_ME_PSIR_104.mat']\n"
     ]
    }
   ],
   "source": [
    "path= './data/Matlab/'\n",
    "subjects= os.listdir(path)\n",
    "for si in range(len(subjects)):\n",
    "    new_path= path+subjects[si]\n",
    "    files= os.listdir(new_path)\n",
    "print('Total number of subjects: ', len(subjects))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'patient_name', 'series_name', 'series_number', 'series_uid', 'series_type', 'zero_based', 'phase_number', 'slice_number', 'study_date', 'lv_endo', 'lv_epi', 'rv_insertion', 'enhancement', 'mvo', 'edema', 'normal', 'skeletal_muscle', 'local', 'raw_image', 'uid', 'trigger_time', 'pixel_size', 'orientation', 'slice_thickness', 'space_between_slice', 'image_position'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Sample: loading the last subject's PSIR file to check its keys '''\n",
    "flge= sio.loadmat(new_path + '/'+ files[2])\n",
    "flge.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Cropped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Standardization and resizing functions '''\n",
    "\n",
    "def std_img(tens):\n",
    "    t_ = (tens-np.amin(tens))/(np.amax(tens)-np.amin(tens))\n",
    "    return t_\n",
    "\n",
    "def resize_volume(img, ex=64):              ### THIS IS CURRENTLY OPERATING ON 2D DATA, 'ex' IS THE EXPECTED SIZE\n",
    "    current_depth = img.shape[0]\n",
    "    current_width = img.shape[1]            \n",
    "\n",
    "    depth_factor = ex / current_depth\n",
    "    width_factor = ex / current_width\n",
    "\n",
    "    factors = (depth_factor, width_factor)\n",
    "\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Initialize all variables to start saving '''\n",
    "\n",
    "path= './data/Matlab/'\n",
    "subjects= os.listdir(path)\n",
    "si = 0\n",
    "yes_save = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saver(si):\n",
    "    saving_folder = './cropped_myo_lge_testing/'                                                            ### RENAME BASED ON FOLDER TO BE SAVED IN\n",
    "    os.makedirs(saving_folder, exist_ok=True)\n",
    "    if yes_save:\n",
    "        try:\n",
    "            os.mkdir(saving_folder +subjects[si])\n",
    "        except:\n",
    "            print('error creating folder; folder already exists: ', os.path.exists(saving_folder +subjects[si]))\n",
    "\n",
    "    new_path= path+subjects[si]\n",
    "    files= os.listdir(new_path)\n",
    "\n",
    "    for fs in files:\n",
    "        # slicer= (75, 175, 45, 145)  ### if you want to manually crop the images\n",
    "        if 'PSIR' in fs or 'LGE' in fs or 'MAG' in fs:\n",
    "            flge= sio.loadmat(new_path+'/'+fs)\n",
    "            try:\n",
    "                __ = flge['series_type']\n",
    "            except:\n",
    "                print('no series for ', fs)\n",
    "                continue\n",
    "            assert flge['series_type']==np.array(['Myocardial Evaluation'])\n",
    "\n",
    "            print(('Length: ', flge['enhancement'][0].shape[0]))\n",
    "\n",
    "            for slice_no in range(flge['enhancement'][0].shape[0]):\n",
    "                scar= np.copy(flge['enhancement'][0][slice_no]).astype('float')\n",
    "                scar[scar==0]=np.nan\n",
    "                if np.nansum(scar)!=0:\n",
    "                # if 1:\n",
    "                    try:\n",
    "                        _= flge['lv_endo'][0][slice_no][0][0]\n",
    "                    except:\n",
    "                        print('couldnt get lv_endo')\n",
    "                        continue\n",
    "                    img_shape= np.transpose(flge['raw_image'][0,slice_no]).shape\n",
    "                    myo_seg_endo= tomni.make_mask.make_mask_contour(img_shape, \n",
    "                                                                    flge['lv_endo'][0][slice_no][0][0][0])    ### CONVERT CONTOURS TO BINARY MASKS\n",
    "                    myo_seg_epi= tomni.make_mask.make_mask_contour(img_shape,\n",
    "                                                                flge['lv_epi'][0][slice_no][0][0][0])         ### CONVERT CONTOURS TO BINARY MASKS\n",
    "                    myo_seg= (myo_seg_epi - myo_seg_endo).astype('float')\n",
    "                    flge['raw_image'][0,slice_no]/=np.amax(flge['raw_image'][0,slice_no])\n",
    "                    myo_seg[myo_seg==0]= np.nan\n",
    "                    fin_img= flge['raw_image'][0,slice_no]*myo_seg\n",
    "                    imc_ = flge['raw_image'][0,slice_no]\n",
    "                    imc_full = std_img(np.array(flge['raw_image'][0,slice_no]))\n",
    "                    fin_img[np.isnan(fin_img)]=0                                                              ### NEEDED TO SAVE\n",
    "\n",
    "\n",
    "                    im= Image.fromarray(np.uint8(cm.gray(fin_img)*255)).convert('L')\n",
    "                    imc__ = Image.fromarray(np.uint8(cm.gray(imc_)*255)).convert('L')\n",
    "                    scar_im= Image.fromarray(np.uint8(cm.gray(scar)*255)).convert('L')\n",
    "\n",
    "                    ''' Get bounding boxes from contours and crop the images. '''\n",
    "                    im.getbbox()                                                                              \n",
    "                    im2 = (std_img(np.array(im.crop(im.getbbox()))))   ## cropped raw image with myo only\n",
    "                    im2 = resize_volume(im2)\n",
    "\n",
    "                    imc = (std_img(np.array(imc__.crop(im.getbbox()))))  ## cropped raw image\n",
    "                    imc = resize_volume(imc)\n",
    "\n",
    "                    sc2 = (std_img(np.array(scar_im.crop(im.getbbox()))))   ## cropped lge segmentation\n",
    "                    sc2 = resize_volume(sc2)\n",
    "\n",
    "                    ''' Use this to visualize the results being stored '''\n",
    "                    # sc2[sc2==0]=np.nan\n",
    "                    # im2[im2==0]=np.nan\n",
    "                    # im2[im2==0]=np.nan\n",
    "                    # plt.imshow(imc, cmap='gray')\n",
    "                    # plt.plot(flge['lv_endo'][0][slice_no][0][0][0][:,0], flge['lv_endo'][0][slice_no][0][0][0][:,1])\n",
    "                    # plt.plot(flge['lv_epi'][0][slice_no][0][0][0][:,0], flge['lv_epi'][0][slice_no][0][0][0][:,1])\n",
    "                    # plt.imshow(myo_seg, cmap='gray')\n",
    "                    # plt.colorbar()\n",
    "                    # plt.imshow(sc2, cmap='jet')\n",
    "                    # plt.imshow(imc_full, cmap='gray')\n",
    "                    # plt.show()\n",
    "                    # # plt.colorbar()\n",
    "                    # plt.axis('off')\n",
    "\n",
    "                    if yes_save:\n",
    "                        \n",
    "                        save_path= saving_folder +subjects[si] + '/raw_'+ str(slice_no) + '.npy'\n",
    "                        im2[np.isnan(im2)]=0\n",
    "                        np.save(save_path, im2)\n",
    "\n",
    "                        save_path= saving_folder +subjects[si] + '/cine_'+ str(slice_no) + '.npy'\n",
    "                        np.save(save_path, imc)\n",
    "\n",
    "                        save_path= saving_folder +subjects[si] + '/cine_whole_'+ str(slice_no) + '.npy'\n",
    "                        np.save(save_path, imc_full)\n",
    "\n",
    "                        save_path=saving_folder +subjects[si] + '/lge_'+ str(slice_no) + '.npy'\n",
    "                        sc2[np.isnan(sc2)]=0\n",
    "                        np.save(save_path, sc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length: ', 12)\n",
      "('Length: ', 10)\n",
      "('Length: ', 11)\n",
      "('Length: ', 14)\n",
      "('Length: ', 9)\n",
      "('Length: ', 9)\n",
      "('Length: ', 11)\n",
      "('Length: ', 14)\n",
      "('Length: ', 11)\n"
     ]
    }
   ],
   "source": [
    "for si in range(len(subjects)):\n",
    "    saver(si)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermediate .npy files used for train-test split, not for directly storing as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44, 64, 64), (44, 64, 64), (44, 64, 64), (44, 224, 224))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_dir = './cropped_myo_lge_testing/'\n",
    "\n",
    "raw_=[]\n",
    "lge_=[]\n",
    "cine_=[]\n",
    "cine_whole_=[]\n",
    "\n",
    "for subject in os.listdir(key_dir):    \n",
    "    files= os.listdir(os.path.join(key_dir, subject))\n",
    "    for f in files:\n",
    "        idx= f[4:list(f).index('.')]\n",
    "        if 'raw' in f:\n",
    "            raw_.append(np.load(os.path.join(key_dir, subject, f)))\n",
    "\n",
    "            lge_f = 'lge_'+str(idx)+'.npy'\n",
    "            lge_.append(np.load(os.path.join(key_dir, subject, lge_f)))\n",
    "\n",
    "            lge_f = 'cine_'+str(idx)+'.npy'\n",
    "            cine_.append(np.load(os.path.join(key_dir, subject, lge_f)))\n",
    "\n",
    "            lge_f = 'cine_whole_'+str(idx)+'.npy'\n",
    "            cine_whole_.append(resize_volume(np.load(os.path.join(key_dir, subject, lge_f)), ex=224))\n",
    "\n",
    "raw_ = np.array(raw_)\n",
    "lge_= np.array(lge_)\n",
    "cine_= np.array(cine_)\n",
    "cine_whole_ = np.array(cine_whole_)\n",
    "\n",
    "raw_.shape, lge_.shape, cine_.shape, cine_whole_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "datas = {'lge_whole': cine_whole_,\n",
    "         'lge_cropped': cine_,\n",
    "         'masked_input': raw_, \n",
    "         'lge_seg': lge_}\n",
    "\n",
    "def default(obj):\n",
    "    if type(obj).__module__ == np.__name__:\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return obj.item()\n",
    "    raise TypeError('Unknown type:', type(obj))\n",
    "\n",
    "with open(\"./sample_inference_data.json\", \"w\") as outfile: \n",
    "    json.dump(datas, outfile, default=default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lge_whole', 'lge_cropped', 'masked_input', 'lge_seg'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_data = json.load(open(\"./sample_inference_data.json\"))\n",
    "inf_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lge_whole= np.array(inf_data['lge_whole']).reshape(44,224,224)\n",
    "x = np.array(inf_data['masked_input']).reshape(44,64,64)\n",
    "y = np.array(inf_data['lge_seg']).reshape(44,64,64)\n",
    "cropped = np.array(inf_data['lge_cropped']).reshape(44,64,64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
